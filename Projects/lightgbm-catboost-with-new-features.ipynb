{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3aa465f",
   "metadata": {
    "papermill": {
     "duration": 0.010207,
     "end_time": "2024-07-31T17:04:06.999143",
     "exception": false,
     "start_time": "2024-07-31T17:04:06.988936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## This notebook is based on the works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd49349",
   "metadata": {
    "papermill": {
     "duration": 0.009367,
     "end_time": "2024-07-31T17:04:07.018339",
     "exception": false,
     "start_time": "2024-07-31T17:04:07.008972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1) **[Naive LightGBM](https://www.kaggle.com/code/bguberfain/naive-lightgbm)** by master [*Bruno G. do Amaral*](https://www.kaggle.com/bguberfain)\n",
    "\n",
    "\n",
    "2) **[Tabular Ensemble: LGBM+Catboost](https://www.kaggle.com/code/snnclsr/tabular-ensemble-lgbm-catboost)** by master [*Sinan Calisir*](https://www.kaggle.com/snnclsr)\n",
    "\n",
    "\n",
    "3) **[ISIC 2024 Skin Cancer - Getting Started](https://www.kaggle.com/code/coderinunderpants/isic-2024-skin-cancer-getting-started)** by contributor [*Joy Banikl*](https://www.kaggle.com/coderinunderpants)\n",
    "\n",
    "\n",
    "4) **[SIC: Tabular model + Image model features](https://www.kaggle.com/code/motono0223/isic-tabular-model-image-model-features)** by master [*motono0223*](https://www.kaggle.com/motono0223)\n",
    "\n",
    "\n",
    "5) **[Only Tabular Features: XGB+CATB+LGBM Ensemble](https://www.kaggle.com/code/rzatemizel/only-tabular-features-xgb-catb-lgbm-ensemble)** by master [*rıza temizel*](https://www.kaggle.com/rzatemizel)\n",
    "\n",
    "\n",
    "7) **[ISIC - Detect Skin Cancer - Let's Learn Together](https://www.kaggle.com/code/dschettler8845/isic-detect-skin-cancer-let-s-learn-together)** by grandmaster [*Darien Schettler*](https://www.kaggle.com/dschettler8845)\n",
    "\n",
    "\n",
    "8) **[ISIC 2024 Skin Cancer Detection hdf5](https://www.kaggle.com/code/mpwolke/isic-2024-skin-cancer-detection-hdf5)** by grandmaster [*Marília Prata*](https://www.kaggle.com/mpwolke)\n",
    "\n",
    "\n",
    "9) **[AI in Dermoscopy. ADAE algorithm.](https://www.kaggle.com/competitions/isic-2024-challenge/discussion/515369)** by grandmaster [*Marília Prata*](https://www.kaggle.com/mpwolke)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f42b6f",
   "metadata": {
    "papermill": {
     "duration": 0.009331,
     "end_time": "2024-07-31T17:04:07.037139",
     "exception": false,
     "start_time": "2024-07-31T17:04:07.027808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here are excerpts from the [comments](https://www.kaggle.com/code/vyacheslavbolotin/isic-tabular-ensemble-lgbm-catboost/comments) section:\n",
    "\n",
    "Yes, I change the ratio. But you see that this is not enough. We stopped at 0.176. A list of experiments that say \"here is everything\", where \"you can clarify\". But there is time, enough time, we must move on. When the master presented one of the latest works here and on this topic the coefficient was 0.175, I added several functions and they added a little to the coefficient. I wrote them and added them intuitively. And how to add a few more functions. In my opinion, auxiliary means are needed - thermal matrices, color matrices, visualization. But if we leave everything on these rails - well, we will get to 0.177, hardly to 0.178. So what? I tried to add functions to the parallel line - no, the coefficient drops. I am not a master here, it is not easy for me to move. Try to add, just like it was here before, one or more parallel lines. I will try to add or remove functions for several days - 3-4. Personally, I can't say anything more. And I can hardly help. Well, I have a couple of ideas - if they work out, they will be published right away. Good luck to you, in your search and in everything. Go. Good luck to everyone!\n",
    "\n",
    "Everything that is presented here, what the developers shared, is similar to each other in one way or another - one is more understandable, another is faster, another is more accurate, and so on, but they still live. And most likely exhausted themselves. Well, it seems to me up to 0.178. Try your approach, or open up previous experience! Carefully. Good luck again.\n",
    "\n",
    "Thanks for the master's rating!\n",
    "This is a copy of the same masters with some additions.\n",
    "Here's what I think: it all started with k>=0.159 from the [work](https://www.kaggle.com/code/bguberfain/naive-lightgbm) of [Bruno G. do Amaral](https://www.kaggle.com/bguberfain), then the [engineering feature](https://www.kaggle.com/code/snnclsr/lgbm-baseline-with-new-features) of [Sinan Calisir](https://www.kaggle.com/snnclsr) was presented and the coefficient increased to k>=0.165, then the work of [motono0223](https://www.kaggle.com/motono0223) was presented, where a [parallel line](https://www.kaggle.com/code/motono0223/isic-tabular-model-image-model-features) was added and the coefficient increased to k>=1.73. Then the [structural approach](https://www.kaggle.com/code/snnclsr/tabular-ensemble-lgbm-catboost) and all this was presented by [Sinan Calisir](https://www.kaggle.com/snnclsr) and the coefficient already reached k>=0.175. My small additions and the coefficient added another 0.01, i.e. became k>=1.76. And at this time our leaderboard showed the coefficient k>=1.85, adding a noticeable 0.09, i.e. almost 7%. What to do next?, is there still time?!, I personally see a line in feature engineering, someone will see another line, for example, a neural network for tabular data has not yet been presented, and is it possible?, someone will see their further work in refining what has already been presented, and so on. In my opinion, further development will consist of the experience and knowledge of each specific community member + their previous work and community competitions. Here, published works of masters and community members as a whole can play a big role. What does it mean to \"warm up the blood\"! Therefore, thank you very much for the assessment, thank you very much for the work where we adopt each other's experience and knowledge, personally, thank you very much! And of course, good luck to everyone!\n",
    "\n",
    "..in my personal ideas about further work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba7f77b",
   "metadata": {
    "papermill": {
     "duration": 0.009184,
     "end_time": "2024-07-31T17:04:07.055844",
     "exception": false,
     "start_time": "2024-07-31T17:04:07.046660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *[Master](https://www.kaggle.com/snnclsr)* **[work](https://www.kaggle.com/code/snnclsr/tabular-ensemble-lgbm-catboost):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3145481",
   "metadata": {
    "papermill": {
     "duration": 0.009162,
     "end_time": "2024-07-31T17:04:07.074472",
     "exception": false,
     "start_time": "2024-07-31T17:04:07.065310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In my previous work [here](https://www.kaggle.com/code/snnclsr/lgbm-baseline-with-new-features), I showed the effectiveness of additional tabular features. Since there are not enough positive samples, every bit of contribution will be important in the final stage.\n",
    "\n",
    "With that motivation, I want to show how ensembles are useful in predictions.\n",
    "\n",
    "**Edit:** New version adds two image model predictions from here: https://www.kaggle.com/code/motono0223/isic-tabular-model-image-model-features and one from my own model (augmentations used [here](https://www.kaggle.com/code/snnclsr/image-augmentations-from-winning-solutions))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc6f5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:04:07.094909Z",
     "iopub.status.busy": "2024-07-31T17:04:07.094566Z",
     "iopub.status.idle": "2024-07-31T17:04:07.105744Z",
     "shell.execute_reply": "2024-07-31T17:04:07.105063Z"
    },
    "papermill": {
     "duration": 0.023672,
     "end_time": "2024-07-31T17:04:07.107653",
     "exception": false,
     "start_time": "2024-07-31T17:04:07.083981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NO_RUN = False\n",
    "\n",
    "import os\n",
    "\n",
    "if NO_RUN and not os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # To save some time.\n",
    "    import pandas as pd\n",
    "    df_sub = pd.read_csv(\"/kaggle/input/isic-2024-challenge/sample_submission.csv\")\n",
    "    df_sub.to_csv(\"submission.csv\", index=False)\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721590b",
   "metadata": {
    "papermill": {
     "duration": 0.009306,
     "end_time": "2024-07-31T17:04:07.127390",
     "exception": false,
     "start_time": "2024-07-31T17:04:07.118084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daccc250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:04:07.147783Z",
     "iopub.status.busy": "2024-07-31T17:04:07.147461Z",
     "iopub.status.idle": "2024-07-31T17:04:12.686277Z",
     "shell.execute_reply": "2024-07-31T17:04:12.685469Z"
    },
    "papermill": {
     "duration": 5.551578,
     "end_time": "2024-07-31T17:04:12.688521",
     "exception": false,
     "start_time": "2024-07-31T17:04:07.136943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import optuna\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "OPTIMIZE_OPTUNA = False\n",
    "SUBSAMPLE = False\n",
    "SUBSAMPLE_RATIO = 0.5 # only effective if SUBSAMPLE=True\n",
    "DISPLAY_FEATURE_IMPORTANCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c9ab38",
   "metadata": {
    "papermill": {
     "duration": 0.009389,
     "end_time": "2024-07-31T17:04:12.707909",
     "exception": false,
     "start_time": "2024-07-31T17:04:12.698520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generating the image level predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8785c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:04:12.728980Z",
     "iopub.status.busy": "2024-07-31T17:04:12.728066Z",
     "iopub.status.idle": "2024-07-31T17:04:26.061069Z",
     "shell.execute_reply": "2024-07-31T17:04:26.059700Z"
    },
    "papermill": {
     "duration": 13.346315,
     "end_time": "2024-07-31T17:04:26.063650",
     "exception": false,
     "start_time": "2024-07-31T17:04:12.717335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST_WEIGHT = /kaggle/input/isic-pytorch-training-baseline-image-only/AUROC0.5171_Loss0.3476_epoch35.bin\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/input/isic-script-inference-effnetv1b0-f313ae/main.py /kaggle/input/isic-pytorch-training-baseline-image-only/AUROC0.5171_Loss0.3476_epoch35.bin\n",
    "!mv submission.csv submission_effnetv1b0.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9df8afd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:04:26.085829Z",
     "iopub.status.busy": "2024-07-31T17:04:26.085462Z",
     "iopub.status.idle": "2024-07-31T17:04:36.308424Z",
     "shell.execute_reply": "2024-07-31T17:04:36.307283Z"
    },
    "papermill": {
     "duration": 10.236936,
     "end_time": "2024-07-31T17:04:36.310862",
     "exception": false,
     "start_time": "2024-07-31T17:04:26.073926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST_WEIGHT = /kaggle/input/isic-pytorch-training-baseline-eva02/AUROC0.5177_Loss0.2829_epoch7.bin\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/input/isic-script-inference-eva02/main.py /kaggle/input/isic-pytorch-training-baseline-eva02/AUROC0.5177_Loss0.2829_epoch7.bin\n",
    "!mv submission.csv submission_eva02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27045c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:04:36.332860Z",
     "iopub.status.busy": "2024-07-31T17:04:36.332546Z",
     "iopub.status.idle": "2024-07-31T17:04:56.677815Z",
     "shell.execute_reply": "2024-07-31T17:04:56.676531Z"
    },
    "papermill": {
     "duration": 20.359205,
     "end_time": "2024-07-31T17:04:56.680448",
     "exception": false,
     "start_time": "2024-07-31T17:04:36.321243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/isic-2024-pl-submission-script-and-preds/pl_submission.py:25: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\r\n",
      "  df_train_meta = pd.read_csv(BASE_DATA_DIR + \"train-metadata.csv\")\r\n"
     ]
    }
   ],
   "source": [
    "# My model\n",
    "!python /kaggle/input/isic-2024-pl-submission-script-and-preds/pl_submission.py\n",
    "!mv submission.csv submission_image3.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa0145",
   "metadata": {
    "papermill": {
     "duration": 0.00993,
     "end_time": "2024-07-31T17:04:56.700999",
     "exception": false,
     "start_time": "2024-07-31T17:04:56.691069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2adaa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:04:56.723587Z",
     "iopub.status.busy": "2024-07-31T17:04:56.723057Z",
     "iopub.status.idle": "2024-07-31T17:05:17.487945Z",
     "shell.execute_reply": "2024-07-31T17:05:17.486935Z"
    },
    "papermill": {
     "duration": 20.779183,
     "end_time": "2024-07-31T17:05:17.490256",
     "exception": false,
     "start_time": "2024-07-31T17:04:56.711073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/2173649023.py:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(\"/kaggle/input/isic-2024-challenge/train-metadata.csv\")\n",
      "/tmp/ipykernel_24/2173649023.py:176: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_eff = pd.read_csv(\"/kaggle/input/isic-inference-effnetv1b0-for-training-data/train_effnetv1b0.csv\")\n",
      "/tmp/ipykernel_24/2173649023.py:179: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_eva = pd.read_csv(\"/kaggle/input/isic-inference-eva02-for-training-data/train_eva02.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/isic-2024-challenge/train-metadata.csv\")\n",
    "df_test = pd.read_csv(\"/kaggle/input/isic-2024-challenge/test-metadata.csv\")\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # New features to try..\n",
    "    # df['np0']                            = np.sqrt(df[\"tbp_lv_areaMM2\"]**2 + df[\"tbp_lv_perimeterMM\"]**2 +df[\"tbp_lv_minorAxisMM\"]**2) / np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n",
    "    \n",
    "    df[\"lesion_size_ratio\"]              = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
    "    df[\"lesion_shape_index\"]             = df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2)\n",
    "    df[\"hue_contrast\"]                   = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n",
    "    df[\"luminance_contrast\"]             = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n",
    "    df[\"lesion_color_difference\"]        = np.sqrt(df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n",
    "    df[\"border_complexity\"]              = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"color_uniformity\"]               = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n",
    "    \n",
    "    df[\"3d_position_distance\"]           = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2) \n",
    "    df[\"perimeter_to_area_ratio\"]        = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n",
    "    df[\"area_to_perimeter_ratio\"]        = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"lesion_visibility_score\"]        = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
    "    df[\"combined_anatomical_site\"]       = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n",
    "    df[\"symmetry_border_consistency\"]    = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
    "    df[\"consistency_symmetry_border\"]    = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"] / (df[\"tbp_lv_symm_2axis\"] + df[\"tbp_lv_norm_border\"])\n",
    "    \n",
    "    df[\"color_consistency\"]              = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n",
    "    df[\"consistency_color\"]              = df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"] / (df[\"tbp_lv_stdL\"] + df[\"tbp_lv_Lext\"])\n",
    "    df[\"size_age_interaction\"]           = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    df[\"hue_color_std_interaction\"]      = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"lesion_severity_index\"]          = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n",
    "    df[\"shape_complexity_index\"]         = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
    "    df[\"color_contrast_index\"]           = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLBnorm\"]\n",
    "    \n",
    "    df[\"log_lesion_area\"]                = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
    "    df[\"normalized_lesion_size\"]         = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n",
    "    df[\"mean_hue_difference\"]            = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "    df[\"std_dev_contrast\"]               = np.sqrt((df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n",
    "    df[\"color_shape_composite_index\"]    = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_symm_2axis\"]) / 3\n",
    "    df[\"3d_lesion_orientation\"]          = np.arctan2(df_train[\"tbp_lv_y\"], df_train[\"tbp_lv_x\"])\n",
    "    df[\"overall_color_difference\"]       = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n",
    "    \n",
    "    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"comprehensive_lesion_index\"]     = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n",
    "    df[\"color_variance_ratio\"]           = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_stdLExt\"]\n",
    "    df[\"border_color_interaction\"]       = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n",
    "    df[\"border_color_interaction_2\"]     = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"] / (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"])\n",
    "    df[\"size_color_contrast_ratio\"]      = df[\"clin_size_long_diam_mm\"] / df[\"tbp_lv_deltaLBnorm\"]\n",
    "    df[\"age_normalized_nevi_confidence\"] = df[\"tbp_lv_nevi_confidence\"] / df[\"age_approx\"]\n",
    "    df[\"age_normalized_nevi_confidence_2\"] = np.sqrt(df[\"clin_size_long_diam_mm\"]**2 + df[\"age_approx\"]**2)\n",
    "    df[\"color_asymmetry_index\"]          = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    \n",
    "    df[\"3d_volume_approximation\"]        = df[\"tbp_lv_areaMM2\"] * np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n",
    "    df[\"color_range\"]                    = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs() + (df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]).abs() + (df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]).abs()\n",
    "    df[\"shape_color_consistency\"]        = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"border_length_ratio\"]            = df[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(df[\"tbp_lv_areaMM2\"] / np.pi))\n",
    "    df[\"age_size_symmetry_index\"]        = df[\"age_approx\"] * df[\"clin_size_long_diam_mm\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"index_age_size_symmetry\"]        = df[\"age_approx\"] * df[\"tbp_lv_areaMM2\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    # Until here..\n",
    "    # df['np1']                           = np.sqrt(df[\"tbp_lv_deltaB\"]**2 + df[\"tbp_lv_deltaL\"]**2 + df[\"tbp_lv_deltaLB\"]**2) / (df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLB\"])\n",
    "    # df['np2']                           = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaLB\"]) / np.sqrt(df[\"tbp_lv_deltaA\"]**2 + df[\"tbp_lv_deltaLB\"]**2)\n",
    "    # df['np3']                           = ?\n",
    "    # ...\n",
    "    # df['npn']                           = ?\n",
    "    \n",
    "    new_num_cols = [\n",
    "        \"lesion_size_ratio\",             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n",
    "        \"lesion_shape_index\",            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n",
    "        \"hue_contrast\",                  # tbp_lv_H                - tbp_lv_Hext              abs\n",
    "        \"luminance_contrast\",            # tbp_lv_L                - tbp_lv_Lext              abs\n",
    "        \"lesion_color_difference\",       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n",
    "        \"border_complexity\",             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n",
    "        \"color_uniformity\",              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n",
    "        \n",
    "        \"3d_position_distance\",          # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n",
    "        \"perimeter_to_area_ratio\",       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n",
    "        \"area_to_perimeter_ratio\",       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n",
    "        \"lesion_visibility_score\",       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n",
    "        # \"combined_anatomical_site\"      # anatom_site_general     + \"_\" + tbp_lv_location ! categorical feature\n",
    "        \"symmetry_border_consistency\",   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n",
    "        \"consistency_symmetry_border\",   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n",
    "        \n",
    "        \"color_consistency\",             # tbp_lv_stdL             / tbp_lv_Lext\n",
    "        \"consistency_color\",             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n",
    "        \"size_age_interaction\",          # clin_size_long_diam_mm  * age_approx\n",
    "        \"hue_color_std_interaction\",     # tbp_lv_H                * tbp_lv_color_std_mean\n",
    "        \"lesion_severity_index\",         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n",
    "        \"shape_complexity_index\",        # border_complexity       + lesion_shape_index\n",
    "        \"color_contrast_index\",          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n",
    "        \n",
    "        \"log_lesion_area\",               # tbp_lv_areaMM2          + 1  np.log\n",
    "        \"normalized_lesion_size\",        # clin_size_long_diam_mm  / age_approx\n",
    "        \"mean_hue_difference\",           # tbp_lv_H                + tbp_lv_Hext    / 2\n",
    "        \"std_dev_contrast\",              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n",
    "        \"color_shape_composite_index\",   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n",
    "        \"3d_lesion_orientation\",         # tbp_lv_y                , tbp_lv_x  np.arctan2\n",
    "        \"overall_color_difference\",      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n",
    "        \n",
    "        \"symmetry_perimeter_interaction\",# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n",
    "        \"comprehensive_lesion_index\",    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n",
    "        \"color_variance_ratio\",          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n",
    "        \"border_color_interaction\",      # tbp_lv_norm_border      * tbp_lv_norm_color\n",
    "        \"border_color_interaction_2\",\n",
    "        \"size_color_contrast_ratio\",     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n",
    "        \"age_normalized_nevi_confidence\",# tbp_lv_nevi_confidence  / age_approx\n",
    "        \"age_normalized_nevi_confidence_2\",\n",
    "        \"color_asymmetry_index\",         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n",
    "        \n",
    "        \"3d_volume_approximation\",       # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n",
    "        \"color_range\",                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n",
    "        \"shape_color_consistency\",       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n",
    "        \"border_length_ratio\",           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n",
    "        \"age_size_symmetry_index\",       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n",
    "         #\"index_age_size_symmetry\",      # age_approx              * sqrt(tbp_lv_areaMM2 * tbp_lv_symm_2axis)\n",
    "        \"index_age_size_symmetry\",       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n",
    "         # Until here..\n",
    "         # \"np0\"\n",
    "         # 'np1',                         # in case of a positive manifestation\n",
    "         # 'np2',                         # in case of a positive manifestation\n",
    "         # 'np3'                          # = ?\n",
    "         # ...\n",
    "         # 'npn'                          # = ?\n",
    "    ]\n",
    "    \n",
    "    new_cat_cols = [\"combined_anatomical_site\"]\n",
    "    \n",
    "    return df, new_num_cols, new_cat_cols\n",
    "\n",
    "\n",
    "num_cols = [\n",
    "    'age_approx',                        # Approximate age of patient at time of imaging.\n",
    "    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n",
    "    'tbp_lv_A',                          # A inside  lesion.+\n",
    "    'tbp_lv_Aext',                       # A outside lesion.+\n",
    "    'tbp_lv_B',                          # B inside  lesion.+\n",
    "    'tbp_lv_Bext',                       # B outside lesion.+ \n",
    "    'tbp_lv_C',                          # Chroma inside  lesion.+\n",
    "    'tbp_lv_Cext',                       # Chroma outside lesion.+\n",
    "    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n",
    "    'tbp_lv_Hext',                       # Hue outside lesion.+\n",
    "    'tbp_lv_L',                          # L inside lesion.+\n",
    "    'tbp_lv_Lext',                       # L outside lesion.+\n",
    "    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n",
    "    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n",
    "    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n",
    "    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaLB',                    #\n",
    "    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n",
    "    'tbp_lv_eccentricity',               # Eccentricity.+\n",
    "    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n",
    "    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n",
    "    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n",
    "    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n",
    "    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n",
    "    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n",
    "    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n",
    "    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n",
    "    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n",
    "    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n",
    "    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n",
    "]\n",
    "\n",
    "df_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].median())\n",
    "df_test [num_cols] = df_test [num_cols].fillna(df_train[num_cols].median())\n",
    "\n",
    "df_train, new_num_cols, new_cat_cols = feature_engineering(df_train.copy())\n",
    "df_test, _, _                        = feature_engineering(df_test.copy())\n",
    "\n",
    "num_cols += new_num_cols\n",
    "\n",
    "# anatom_site_general\n",
    "cat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"] + new_cat_cols\n",
    "train_cols = num_cols + cat_cols\n",
    "\n",
    "df_eff = pd.read_csv(\"/kaggle/input/isic-inference-effnetv1b0-for-training-data/train_effnetv1b0.csv\")\n",
    "df_eff = df_eff[[\"target_effnetv1b0\"]]\n",
    "\n",
    "df_eva = pd.read_csv(\"/kaggle/input/isic-inference-eva02-for-training-data/train_eva02.csv\")\n",
    "df_eva = df_eva[[\"target_eva02\"]]\n",
    "\n",
    "df_image_3 = pd.read_csv(\"/kaggle/input/isic-2024-pl-submission-script-and-preds/train_preds.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_train[\"target_effnetv1b0\"] = df_eff[\"target_effnetv1b0\"]\n",
    "df_train[\"target_eva02\"] = df_eva[\"target_eva02\"]\n",
    "df_train[\"target_3\"] = df_image_3[\"pred\"]\n",
    "\n",
    "# ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~\n",
    "# approximately the same FE does not give anything yet the correct \n",
    "# one asks to add one or more parallel lines\n",
    "# ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_cols += [\"target_effnetv1b0\",\"target_eva02\", \"target_3\"]\n",
    "\n",
    "category_encoder = OrdinalEncoder(\n",
    "    categories='auto',\n",
    "    dtype=int,\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-2,\n",
    "    encoded_missing_value=-1,\n",
    ")\n",
    "\n",
    "X_cat = category_encoder.fit_transform(df_train[cat_cols])\n",
    "for c, cat_col in enumerate(cat_cols):\n",
    "    df_train[cat_col] = X_cat[:, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427f71a",
   "metadata": {
    "papermill": {
     "duration": 0.010148,
     "end_time": "2024-07-31T17:05:17.511327",
     "exception": false,
     "start_time": "2024-07-31T17:05:17.501179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daba56c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:05:17.534655Z",
     "iopub.status.busy": "2024-07-31T17:05:17.534061Z",
     "iopub.status.idle": "2024-07-31T17:05:19.749667Z",
     "shell.execute_reply": "2024-07-31T17:05:19.748685Z"
    },
    "papermill": {
     "duration": 2.229232,
     "end_time": "2024-07-31T17:05:19.752038",
     "exception": false,
     "start_time": "2024-07-31T17:05:17.522806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "\n",
    "gkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "if SUBSAMPLE:\n",
    "    df_pos = df_train[df_train[\"target\"] == 1]\n",
    "    df_neg = df_train[df_train[\"target\"] == 0]\n",
    "    df_neg = df_neg.sample(frac=SUBSAMPLE_RATIO, random_state=42)\n",
    "    df_train = pd.concat([df_pos, df_neg]).sample(frac=1.0, random_state=42).reset_index(drop=True)    \n",
    "\n",
    "df_train[\"fold\"] = -1\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(gkf.split(df_train, df_train[\"target\"], groups=df_train[\"patient_id\"])):\n",
    "    df_train.loc[val_idx, \"fold\"] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36782c18",
   "metadata": {
    "papermill": {
     "duration": 0.01058,
     "end_time": "2024-07-31T17:05:19.773560",
     "exception": false,
     "start_time": "2024-07-31T17:05:19.762980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Competition Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f08f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:05:19.796173Z",
     "iopub.status.busy": "2024-07-31T17:05:19.795840Z",
     "iopub.status.idle": "2024-07-31T17:05:19.804403Z",
     "shell.execute_reply": "2024-07-31T17:05:19.803509Z"
    },
    "papermill": {
     "duration": 0.022277,
     "end_time": "2024-07-31T17:05:19.806169",
     "exception": false,
     "start_time": "2024-07-31T17:05:19.783892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(solution.values)-1)\n",
    "    v_pred = np.array([1.0 - x for x in submission.values])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n",
    "\n",
    "def custom_lgbm_metric(y_true, y_hat):\n",
    "    # TODO: Refactor with the above.\n",
    "    min_tpr = 0.80\n",
    "    v_gt = abs(y_true-1)\n",
    "    v_pred = np.array([1.0 - x for x in y_hat])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return \"pauc80\", partial_auc, True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ebf7e",
   "metadata": {
    "papermill": {
     "duration": 0.010199,
     "end_time": "2024-07-31T17:05:19.826943",
     "exception": false,
     "start_time": "2024-07-31T17:05:19.816744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd454cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:05:19.849322Z",
     "iopub.status.busy": "2024-07-31T17:05:19.848947Z",
     "iopub.status.idle": "2024-07-31T17:05:19.858202Z",
     "shell.execute_reply": "2024-07-31T17:05:19.857367Z"
    },
    "papermill": {
     "duration": 0.022567,
     "end_time": "2024-07-31T17:05:19.860024",
     "exception": false,
     "start_time": "2024-07-31T17:05:19.837457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\":         \"binary\",\n",
    "        # \"metric\":           \"custom\",\n",
    "        \"verbosity\":         -1,\n",
    "        \"boosting_type\":     \"gbdt\",\n",
    "        \"lambda_l1\":         trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\":         trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\":        trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\":  trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\":  trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\":      trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"device\":            \"gpu\"\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for fold in range(N_SPLITS):\n",
    "        _df_train = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n",
    "        _df_valid = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n",
    "        dtrain = lgb.Dataset(_df_train[train_cols], label=_df_train[\"target\"])\n",
    "        gbm = lgb.train(param, dtrain)\n",
    "        preds = gbm.predict(_df_valid[train_cols])\n",
    "        score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n",
    "        scores.append(score)\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5096b9b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:05:19.881851Z",
     "iopub.status.busy": "2024-07-31T17:05:19.881575Z",
     "iopub.status.idle": "2024-07-31T17:05:19.887055Z",
     "shell.execute_reply": "2024-07-31T17:05:19.886243Z"
    },
    "papermill": {
     "duration": 0.018493,
     "end_time": "2024-07-31T17:05:19.888884",
     "exception": false,
     "start_time": "2024-07-31T17:05:19.870391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if OPTIMIZE_OPTUNA:\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=21)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d0e07fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:05:19.910662Z",
     "iopub.status.busy": "2024-07-31T17:05:19.910380Z",
     "iopub.status.idle": "2024-07-31T17:06:46.037867Z",
     "shell.execute_reply": "2024-07-31T17:06:46.036843Z"
    },
    "papermill": {
     "duration": 86.140878,
     "end_time": "2024-07-31T17:06:46.040114",
     "exception": false,
     "start_time": "2024-07-31T17:05:19.899236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - Partial AUC Score: 0.17992\n",
      "fold: 1 - Partial AUC Score: 0.18788\n",
      "fold: 2 - Partial AUC Score: 0.19385\n",
      "fold: 3 - Partial AUC Score: 0.17907\n",
      "fold: 4 - Partial AUC Score: 0.18907\n"
     ]
    }
   ],
   "source": [
    "# lgb_params = {\n",
    "#     'objective': 'binary',\n",
    "#     # \"random_state\": 42,\n",
    "#     \"n_estimators\": 1500,\n",
    "#     'learning_rate': 0.001,\n",
    "#     'bagging_freq': 1,\n",
    "#     'pos_bagging_fraction': 0.75,\n",
    "#     'neg_bagging_fraction': 0.05,\n",
    "#     'feature_fraction': 0.6,\n",
    "#     'lambda_l1': 0.2,\n",
    "#     'lambda_l2': 0.7,\n",
    "#     'num_leaves': 35,\n",
    "#     \"min_data_in_leaf\": 50,\n",
    "#     \"verbosity\": -1,\n",
    "#     \"device\": \"gpu\"\n",
    "#     # \"extra_trees\": True\n",
    "# }\n",
    "# new_params =  {\n",
    "#     \"objective\": \"binary\",\n",
    "#     \"verbosity\": -1,\n",
    "#     \"boosting_type\": \"gbdt\",\n",
    "#     \"n_estimators\": 2000,\n",
    "#     'learning_rate': 0.03,    \n",
    "#     'lambda_l1': 0.0004681884533249742, \n",
    "#     'lambda_l2': 8.765240856362274, \n",
    "#     'num_leaves': 136, \n",
    "#     'feature_fraction': 0.5392005444882538, \n",
    "#     'bagging_fraction': 0.9577412548866563, \n",
    "#     'bagging_freq': 6,\n",
    "#     'min_child_samples': 60,\n",
    "#     \"device\": \"cpu\"\n",
    "# }\n",
    "new_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"n_estimators\": 200,\n",
    "    'learning_rate': 0.05,    \n",
    "    'lambda_l1': 0.0004681884533249742, \n",
    "    'lambda_l2': 8.765240856362274, \n",
    "    'num_leaves': 136, \n",
    "    'feature_fraction': 0.5392005444882538, \n",
    "    'bagging_fraction': 0.9577412548866563, \n",
    "    'bagging_freq': 6,\n",
    "    'min_child_samples': 60,\n",
    "    \"device\": \"gpu\"\n",
    "}\n",
    "lgb_scores = []\n",
    "lgb_models = []\n",
    "oof_df = pd.DataFrame()\n",
    "for fold in range(N_SPLITS):\n",
    "    _df_train = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n",
    "    _df_valid = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n",
    "    model = lgb.LGBMClassifier(**new_params)\n",
    "    # model = VotingClassifier([(f\"lgb_{i}\", lgb.LGBMClassifier(random_state=i, **new_params)) for i in range(7)], voting=\"soft\")\n",
    "    model.fit(_df_train[train_cols], _df_train[\"target\"])\n",
    "    preds = model.predict_proba(_df_valid[train_cols])[:, 1]\n",
    "    score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n",
    "    print(f\"fold: {fold} - Partial AUC Score: {score:.5f}\")\n",
    "    lgb_models.append(model)\n",
    "    oof_single = _df_valid[[\"isic_id\", \"target\"]].copy()\n",
    "    oof_single[\"pred\"] = preds\n",
    "    oof_df = pd.concat([oof_df, oof_single])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28924175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:06:46.065977Z",
     "iopub.status.busy": "2024-07-31T17:06:46.065667Z",
     "iopub.status.idle": "2024-07-31T17:06:46.071292Z",
     "shell.execute_reply": "2024-07-31T17:06:46.070463Z"
    },
    "papermill": {
     "duration": 0.020744,
     "end_time": "2024-07-31T17:06:46.073230",
     "exception": false,
     "start_time": "2024-07-31T17:06:46.052486",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mrs = []\n",
    "\n",
    "# for j in range(7):\n",
    "    \n",
    "#     lgb_params = {\n",
    "#         \"objective\":         \"binary\",\n",
    "#         \"boosting_type\":     \"gbdt\",\n",
    "#         \"n_estimators\":      random.choice([500,1000,1500,2000]),\n",
    "#         'learning_rate':     random.choice([0.003,0.005,0.01,0.03,0.05]),  \n",
    "#         'lambda_l1':         random.choice([0.001,0.0001,0.00047,0.00077,0.00087]),\n",
    "#         'lambda_l2':         random.choice([0.7,1.4,3,4,5,7,8.77]),\n",
    "#         'num_leaves':        random.choice([50,100,150,200,250]),\n",
    "# #         'feature_fraction':  random.choice([0,34,0.54,0.74,0.85]),\n",
    "# #         'bagging_fraction':  random.choice([0.77,0.85,0.95]),\n",
    "#         'bagging_freq':      random.choice([5,6,7,8]),\n",
    "#         'min_child_samples': random.choice([40,50,60,70]),\n",
    "#         \"verbosity\":         -1,\n",
    "#         \"device\": \"gpu\"\n",
    "#     }\n",
    "    \n",
    "#     lgb_scores = []\n",
    "#     lgb_models = []\n",
    "    \n",
    "#     oof_df = pd.DataFrame()\n",
    "#     for fold in range(N_SPLITS):\n",
    "#         _df_train = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n",
    "#         _df_valid = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n",
    "#         model = VotingClassifier([(f\"lgb_{i}\", lgb.LGBMClassifier(random_state=i, **lgb_params)) for i in range(3)], voting=\"soft\")\n",
    "#         model.fit(_df_train[train_cols], _df_train[\"target\"])\n",
    "#         preds = model.predict_proba(_df_valid[train_cols])[:, 1]\n",
    "#         score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n",
    "#         print(f\"fold: {fold} - Partial AUC Score: {score:.5f}\")\n",
    "#         lgb_scores.append(score)\n",
    "#         lgb_models.append(model)\n",
    "\n",
    "#     mrs.append({'models':lgb_models, 'params':lgb_params, 'scores':lgb_scores})\n",
    "#     print('\\n',np.mean(lgb_scores),'\\n')\n",
    "    \n",
    "# _score,i,j  = -1,0,0\n",
    "\n",
    "# for mr in mrs:\n",
    "#     _mean = np.mean(mr['scores'])\n",
    "#     if _mean > _score: \n",
    "#         _score = _mean\n",
    "#         j = i\n",
    "#     i += 1\n",
    "    \n",
    "# lgb_scores = mrs[j]['scores']\n",
    "# lgb_models = mrs[j]['models']\n",
    "# lgb_params = mrs[j]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "609f5732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:06:46.098704Z",
     "iopub.status.busy": "2024-07-31T17:06:46.098386Z",
     "iopub.status.idle": "2024-07-31T17:06:46.308017Z",
     "shell.execute_reply": "2024-07-31T17:06:46.307098Z"
    },
    "papermill": {
     "duration": 0.224666,
     "end_time": "2024-07-31T17:06:46.309979",
     "exception": false,
     "start_time": "2024-07-31T17:06:46.085313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Score: 0.18477\n"
     ]
    }
   ],
   "source": [
    "lgbm_score = comp_score(oof_df[\"target\"], oof_df[\"pred\"], \"\")\n",
    "print(f\"LGBM Score: {lgbm_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d47894e",
   "metadata": {
    "papermill": {
     "duration": 0.0126,
     "end_time": "2024-07-31T17:06:46.335413",
     "exception": false,
     "start_time": "2024-07-31T17:06:46.322813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LGBM Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd421bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:06:46.361408Z",
     "iopub.status.busy": "2024-07-31T17:06:46.361032Z",
     "iopub.status.idle": "2024-07-31T17:06:46.366889Z",
     "shell.execute_reply": "2024-07-31T17:06:46.366024Z"
    },
    "papermill": {
     "duration": 0.021014,
     "end_time": "2024-07-31T17:06:46.368702",
     "exception": false,
     "start_time": "2024-07-31T17:06:46.347688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DISPLAY_FEATURE_IMPORTANCE:\n",
    "    # Make sure that this is a single model, not voting classifier. Will handle that later on.\n",
    "    importances = np.mean([model.feature_importances_ for model in lgb_models], 0)\n",
    "    df_imp = pd.DataFrame({\"feature\": model.feature_name_, \"importance\": importances}).sort_values(\"importance\").reset_index(drop=True)\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.barh(df_imp[\"feature\"], df_imp[\"importance\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa50c22",
   "metadata": {
    "papermill": {
     "duration": 0.012308,
     "end_time": "2024-07-31T17:06:46.395672",
     "exception": false,
     "start_time": "2024-07-31T17:06:46.383364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3547a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:06:46.422231Z",
     "iopub.status.busy": "2024-07-31T17:06:46.421480Z",
     "iopub.status.idle": "2024-07-31T17:06:46.431726Z",
     "shell.execute_reply": "2024-07-31T17:06:46.430834Z"
    },
    "papermill": {
     "duration": 0.02554,
     "end_time": "2024-07-31T17:06:46.433581",
     "exception": false,
     "start_time": "2024-07-31T17:06:46.408041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\":         trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\":             trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\":     trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\":    trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
    "        # \"task_type\":       \"GPU\",\n",
    "        # \"used_ram_limit\":  \"3gb\",\n",
    "    }\n",
    "    \n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    \n",
    "    if param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"]           = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for fold in range(N_SPLITS):\n",
    "        _df_train = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n",
    "        _df_valid = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n",
    "        gbm = cb.CatBoostClassifier(**param)\n",
    "        gbm.fit(_df_train[train_cols], _df_train[\"target\"], eval_set=[(_df_valid[train_cols], _df_valid[\"target\"])], verbose=0, early_stopping_rounds=100)\n",
    "        preds = gbm.predict(_df_valid[train_cols])\n",
    "        score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n",
    "        scores.append(score)\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb233d8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:06:46.460489Z",
     "iopub.status.busy": "2024-07-31T17:06:46.459647Z",
     "iopub.status.idle": "2024-07-31T17:06:46.465791Z",
     "shell.execute_reply": "2024-07-31T17:06:46.464895Z"
    },
    "papermill": {
     "duration": 0.021522,
     "end_time": "2024-07-31T17:06:46.467622",
     "exception": false,
     "start_time": "2024-07-31T17:06:46.446100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if OPTIMIZE_OPTUNA:\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=21, timeout=500)\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd4daf59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:06:46.493860Z",
     "iopub.status.busy": "2024-07-31T17:06:46.493579Z",
     "iopub.status.idle": "2024-07-31T17:06:46.498039Z",
     "shell.execute_reply": "2024-07-31T17:06:46.497243Z"
    },
    "papermill": {
     "duration": 0.019657,
     "end_time": "2024-07-31T17:06:46.499941",
     "exception": false,
     "start_time": "2024-07-31T17:06:46.480284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cb_params = {\n",
    "#     'objective': 'Logloss',\n",
    "#     # \"random_state\": 42,\n",
    "#     # \"colsample_bylevel\": 0.3, # 0.01, 0.1\n",
    "#     \"iterations\": 400,\n",
    "#     \"learning_rate\": 0.05,\n",
    "#     \"cat_features\": cat_cols,\n",
    "#     \"max_depth\": 8,\n",
    "#     \"l2_leaf_reg\": 5,\n",
    "#     \"task_type\": \"GPU\",\n",
    "#     # \"scale_pos_weight\": 2,\n",
    "#     \"verbose\": 0,\n",
    "# }\n",
    "# cb_scores = []\n",
    "# cb_models = []\n",
    "# for fold in range(N_SPLITS):\n",
    "#     _df_train = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n",
    "#     _df_valid = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n",
    "#     # model = cb.CatBoostClassifier(**cb_params)\n",
    "#     model = VotingClassifier([(f\"cb_{i}\", cb.CatBoostClassifier(random_state=i, **cb_params)) for i in range(3)], voting=\"soft\")\n",
    "#     # eval_set=(_df_valid[train_cols], _df_valid[\"target\"]), early_stopping_rounds=50\n",
    "#     model.fit(_df_train[train_cols], _df_train[\"target\"])\n",
    "#     preds = model.predict_proba(_df_valid[train_cols])[:, 1]\n",
    "#     score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n",
    "#     print(f\"fold: {fold} - Partial AUC Score: {score:.5f}\")\n",
    "#     cb_scores.append(score)\n",
    "#     cb_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9298611e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:06:46.525997Z",
     "iopub.status.busy": "2024-07-31T17:06:46.525747Z",
     "iopub.status.idle": "2024-07-31T17:18:01.234073Z",
     "shell.execute_reply": "2024-07-31T17:18:01.233031Z"
    },
    "papermill": {
     "duration": 674.724159,
     "end_time": "2024-07-31T17:18:01.236439",
     "exception": false,
     "start_time": "2024-07-31T17:06:46.512280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - Partial AUC Score: 0.17615\n",
      "fold: 1 - Partial AUC Score: 0.18257\n",
      "fold: 2 - Partial AUC Score: 0.19228\n",
      "fold: 3 - Partial AUC Score: 0.16693\n",
      "fold: 4 - Partial AUC Score: 0.18619\n",
      "\n",
      " 0.18082609486785006 \n",
      "\n",
      "fold: 0 - Partial AUC Score: 0.17750\n",
      "fold: 1 - Partial AUC Score: 0.18500\n",
      "fold: 2 - Partial AUC Score: 0.19435\n",
      "fold: 3 - Partial AUC Score: 0.17542\n",
      "fold: 4 - Partial AUC Score: 0.18462\n",
      "\n",
      " 0.18337649806256123 \n",
      "\n",
      "fold: 0 - Partial AUC Score: 0.17955\n",
      "fold: 1 - Partial AUC Score: 0.18478\n",
      "fold: 2 - Partial AUC Score: 0.19392\n",
      "fold: 3 - Partial AUC Score: 0.17105\n",
      "fold: 4 - Partial AUC Score: 0.18596\n",
      "\n",
      " 0.18305264933926554 \n",
      "\n",
      "fold: 0 - Partial AUC Score: 0.17065\n",
      "fold: 1 - Partial AUC Score: 0.18697\n",
      "fold: 2 - Partial AUC Score: 0.19205\n",
      "fold: 3 - Partial AUC Score: 0.17443\n",
      "fold: 4 - Partial AUC Score: 0.18882\n",
      "\n",
      " 0.18258664799061256 \n",
      "\n",
      "fold: 0 - Partial AUC Score: 0.18043\n",
      "fold: 1 - Partial AUC Score: 0.18692\n",
      "fold: 2 - Partial AUC Score: 0.19416\n",
      "fold: 3 - Partial AUC Score: 0.17364\n",
      "fold: 4 - Partial AUC Score: 0.18835\n",
      "\n",
      " 0.18470140155492598 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mrs = []\n",
    "\n",
    "for j in range(random.choice([3,4,5])):\n",
    "    cb_params = {\n",
    "        'objective':         'Logloss',\n",
    "        # \"random_state\":      42,\n",
    "        # \"colsample_bylevel\": 0.3, # 0.01, 0.1\n",
    "        \"iterations\":         random.choice([400,500,700, 800, 900]),\n",
    "        \"learning_rate\":      random.choice([0.05,0.04,0.03,0.02,0.01]),\n",
    "        \"cat_features\":       cat_cols,\n",
    "        \"max_depth\":          random.choice([7,8,9]),\n",
    "        \"l2_leaf_reg\":        random.choice([5,4,7]),\n",
    "        \"task_type\":          \"GPU\",\n",
    "        # \"scale_pos_weight\":  2,\n",
    "        \"verbose\":            0,\n",
    "    }\n",
    "\n",
    "    cb_scores = []\n",
    "    cb_models = []\n",
    "\n",
    "    for fold in range(N_SPLITS):\n",
    "        _df_train = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n",
    "        _df_valid = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n",
    "        model = cb.CatBoostClassifier(**cb_params)\n",
    "        # model = VotingClassifier([(f\"cb_{i}\", cb.CatBoostClassifier(random_state=i, **cb_params)) for i in range(3)], voting=\"soft\")\n",
    "        model.fit(_df_train[train_cols], _df_train[\"target\"])\n",
    "        preds = model.predict_proba(_df_valid[train_cols])[:, 1]\n",
    "        score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n",
    "        print(f\"fold: {fold} - Partial AUC Score: {score:.5f}\")\n",
    "        cb_scores.append(score)\n",
    "        cb_models.append(model)\n",
    "        \n",
    "    mrs.append({'models':cb_models, 'params':cb_params, 'scores':cb_scores})\n",
    "    print('\\n',np.mean(cb_scores),'\\n')\n",
    "    \n",
    "_score,i,j  = -1,0,0\n",
    "\n",
    "for mr in mrs:\n",
    "    _mean = np.mean(mr['scores'])\n",
    "    if _mean > _score: \n",
    "        _score = _mean\n",
    "        j = i\n",
    "    i += 1\n",
    "    \n",
    "cb_scores = mrs[j]['scores']\n",
    "cb_models = mrs[j]['models']\n",
    "cb_params = mrs[j]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "816196c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:18:01.268434Z",
     "iopub.status.busy": "2024-07-31T17:18:01.268105Z",
     "iopub.status.idle": "2024-07-31T17:18:01.273317Z",
     "shell.execute_reply": "2024-07-31T17:18:01.272364Z"
    },
    "papermill": {
     "duration": 0.02255,
     "end_time": "2024-07-31T17:18:01.275151",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.252601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Score: 0.18470\n",
      "CatBoost Param: {'objective': 'Logloss', 'iterations': 400, 'learning_rate': 0.05, 'cat_features': ['sex', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'combined_anatomical_site'], 'max_depth': 8, 'l2_leaf_reg': 5, 'task_type': 'GPU', 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "cb_score = np.mean(cb_scores)\n",
    "print(f\"CatBoost Score: {cb_score:.5f}\")\n",
    "print(f\"CatBoost Param: {cb_params:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27157327",
   "metadata": {
    "papermill": {
     "duration": 0.015986,
     "end_time": "2024-07-31T17:18:01.305835",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.289849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CatBoost Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "818abf4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:18:01.336982Z",
     "iopub.status.busy": "2024-07-31T17:18:01.336601Z",
     "iopub.status.idle": "2024-07-31T17:18:01.343417Z",
     "shell.execute_reply": "2024-07-31T17:18:01.342509Z"
    },
    "papermill": {
     "duration": 0.025052,
     "end_time": "2024-07-31T17:18:01.345538",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.320486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DISPLAY_FEATURE_IMPORTANCE:\n",
    "    # Same here.\n",
    "    importances = np.mean([model.feature_importances_ for model in cb_models], 0)\n",
    "    df_imp = pd.DataFrame({\"feature\": model.feature_names_, \"importance\": importances}).sort_values(\"importance\").reset_index(drop=True)\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.barh(df_imp[\"feature\"], df_imp[\"importance\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c68f0",
   "metadata": {
    "papermill": {
     "duration": 0.014482,
     "end_time": "2024-07-31T17:18:01.375598",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.361116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00198666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:18:01.406886Z",
     "iopub.status.busy": "2024-07-31T17:18:01.406088Z",
     "iopub.status.idle": "2024-07-31T17:18:01.414397Z",
     "shell.execute_reply": "2024-07-31T17:18:01.413610Z"
    },
    "papermill": {
     "duration": 0.026159,
     "end_time": "2024-07-31T17:18:01.416434",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.390275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_cat = category_encoder.transform(df_test[cat_cols])\n",
    "for c, cat_col in enumerate(cat_cols):\n",
    "    df_test[cat_col] = X_cat[:, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2e315fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:18:01.448019Z",
     "iopub.status.busy": "2024-07-31T17:18:01.447323Z",
     "iopub.status.idle": "2024-07-31T17:18:01.459387Z",
     "shell.execute_reply": "2024-07-31T17:18:01.458602Z"
    },
    "papermill": {
     "duration": 0.029818,
     "end_time": "2024-07-31T17:18:01.461319",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.431501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "df_eff = pd.read_csv(\"submission_effnetv1b0.csv\")\n",
    "df_test[\"target_effnetv1b0\"] = df_eff[\"target\"]\n",
    "\n",
    "df_eva = pd.read_csv(\"submission_eva02.csv\")\n",
    "df_test[\"target_eva02\"] = df_eva[\"target\"]\n",
    "\n",
    "df_3 = pd.read_csv(\"submission_image3.csv\")\n",
    "df_test[\"target_3\"] = df_3[\"target\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~\n",
    "# approximately the same FE does not give anything yet the correct\n",
    "# one asks to add one or more parallel lines\n",
    "# ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e3bbfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:18:01.491956Z",
     "iopub.status.busy": "2024-07-31T17:18:01.491662Z",
     "iopub.status.idle": "2024-07-31T17:18:01.556330Z",
     "shell.execute_reply": "2024-07-31T17:18:01.555398Z"
    },
    "papermill": {
     "duration": 0.082662,
     "end_time": "2024-07-31T17:18:01.558787",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.476125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_preds = np.mean([model.predict_proba(df_test[train_cols])[:, 1] for model in lgb_models], 0)\n",
    "cb_preds  = np.mean([model.predict_proba(df_test[train_cols])[:, 1] for model in cb_models],  0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0224ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:18:01.595102Z",
     "iopub.status.busy": "2024-07-31T17:18:01.594764Z",
     "iopub.status.idle": "2024-07-31T17:18:01.600069Z",
     "shell.execute_reply": "2024-07-31T17:18:01.599149Z"
    },
    "papermill": {
     "duration": 0.023614,
     "end_time": "2024-07-31T17:18:01.601984",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.578370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds = lgb_preds * 0.555 + cb_preds * 0.445 # V7 : 0.174 + random CAT\n",
    "# preds = lgb_preds * 0.558 + cb_preds * 0.442 # V8 : 0.176 \n",
    "\n",
    "# preds = lgb_preds * 0.565 + cb_preds * 0.435 # V9 : 0.175 + Strictly, danger !!!\n",
    "# preds = lgb_preds * 0.545 + cb_preds * 0.455 # V11: 0.175 + Strictly, danger !!!\n",
    "\n",
    "# preds = lgb_preds * 0.565 + cb_preds * 0.435 # V12: 0.173 + Strictly, danger !!!\n",
    "# preds = lgb_preds * 0.545 + cb_preds * 0.455 # V13: 0.175 + Strictly, danger !!!\n",
    "\n",
    "# preds = lgb_preds * 0.54  + cb_preds * 0.46  # V14: 0.175 + Strictly, danger !!!\n",
    "\n",
    "# preds = lgb_preds * 0.56  + cb_preds * 0.44  # V15: 0.168 + Strictly, danger !!!\n",
    "# preds = lgb_preds * 0.56  + cb_preds * 0.44  # V16: 0.176\n",
    "\n",
    "# preds = lgb_preds * 0.70  + cb_preds * 0.30  # V17: 0.175\n",
    "# preds = lgb_preds * 0.30  + cb_preds * 0.70  # V18: 0.176\n",
    "\n",
    "# preds = lgb_preds * 0.85  + cb_preds * 0.15  # V19: 0.174\n",
    "# preds = lgb_preds * 0.15  + cb_preds * 0.85  # V20: 0.175\n",
    "\n",
    "# preds = lgb_preds * 0.40  + cb_preds * 0.60  # V21: 0.175\n",
    "\n",
    "# preds = lgb_preds * 0.45 + cb_preds * 0.55   # V22: 0.175\n",
    "\n",
    "preds = lgb_preds * 0.558 + cb_preds * 0.442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "404bb2ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:18:01.633512Z",
     "iopub.status.busy": "2024-07-31T17:18:01.632980Z",
     "iopub.status.idle": "2024-07-31T17:18:01.659334Z",
     "shell.execute_reply": "2024-07-31T17:18:01.658400Z"
    },
    "papermill": {
     "duration": 0.044488,
     "end_time": "2024-07-31T17:18:01.661630",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.617142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id    target\n",
       "0  ISIC_0015657  0.000057\n",
       "1  ISIC_0015729  0.000011\n",
       "2  ISIC_0015740  0.000011"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.read_csv(\"/kaggle/input/isic-2024-challenge/sample_submission.csv\")\n",
    "df_sub[\"target\"] = preds\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abb3b338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T17:18:01.698386Z",
     "iopub.status.busy": "2024-07-31T17:18:01.698050Z",
     "iopub.status.idle": "2024-07-31T17:18:01.704595Z",
     "shell.execute_reply": "2024-07-31T17:18:01.703772Z"
    },
    "papermill": {
     "duration": 0.025042,
     "end_time": "2024-07-31T17:18:01.706721",
     "exception": false,
     "start_time": "2024-07-31T17:18:01.681679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5406640,
     "sourceId": 8982084,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5415918,
     "sourceId": 8991790,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 186147615,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187730674,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 188543089,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 188543756,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 188602899,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 188603204,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 838.453267,
   "end_time": "2024-07-31T17:18:02.644652",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-31T17:04:04.191385",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
